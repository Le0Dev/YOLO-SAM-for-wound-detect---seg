{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2c6cdb",
   "metadata": {},
   "source": [
    "Inference Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import SamProcessor, SamModel, SamConfig\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def extract_results_info(results):\n",
    "    info_dict = {}\n",
    "    info_dict['path'] = results[0].path\n",
    "    info_dict['shape'] = results[0].orig_shape\n",
    "    boxes = results[0].boxes\n",
    "    bounding_boxes = boxes.xyxy.tolist()\n",
    "    converted_boxes = []\n",
    "    for box in bounding_boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        converted_boxes.append([x_min, y_min, x_max, y_max])\n",
    "    info_dict['bounding_boxes'] = converted_boxes\n",
    "    return info_dict\n",
    "\n",
    "def expand_bounding_boxes(bounding_boxes, image_shape, expansion_ratio=0.1):\n",
    "    expanded_boxes = []\n",
    "    for box in bounding_boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        new_x_min = max(0, x_min - width * expansion_ratio)\n",
    "        new_y_min = max(0, y_min - height * expansion_ratio)\n",
    "        new_x_max = min(image_shape[1], x_max + width * expansion_ratio)\n",
    "        new_y_max = min(image_shape[0], y_max + height * expansion_ratio)\n",
    "        expanded_boxes.append([new_x_min, new_y_min, new_x_max, new_y_max])\n",
    "    return expanded_boxes\n",
    "\n",
    "def perform_segmentation_with_box(image_path, box):\n",
    "    test_image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(test_image, input_boxes=[[box]], return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_sam(**inputs, multimask_output=False)\n",
    "    medsam_seg_prob = torch.sigmoid(outputs.pred_masks.squeeze(1))\n",
    "    medsam_seg_prob = medsam_seg_prob.cpu().numpy().squeeze()\n",
    "    medsam_seg = (medsam_seg_prob > 0.5).astype(np.uint8)\n",
    "    return medsam_seg\n",
    "\n",
    "def merge_masks(predicted_masks):\n",
    "    if predicted_masks:\n",
    "        merged_mask = np.zeros_like(predicted_masks[0], dtype=np.uint8)\n",
    "        for mask in predicted_masks:\n",
    "            merged_mask[mask != 0] = 1\n",
    "    else:\n",
    "        merged_mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "    return merged_mask\n",
    "\n",
    "def process_image(image_path, yolo_model, sam_model, sam_processor, device):\n",
    "    results = yolo_model.predict(source=[image_path], imgsz=512, conf=0.3, verbose=False)\n",
    "    results_info = extract_results_info(results)\n",
    "\n",
    "    image = Image.open(results_info['path'])\n",
    "    image_shape = image.size[::-1]\n",
    "\n",
    "    expanded_boxes = expand_bounding_boxes(results_info['bounding_boxes'], image_shape)\n",
    "\n",
    "    predicted_masks = []\n",
    "    for box in expanded_boxes:\n",
    "        seg_mask = perform_segmentation_with_box(results_info['path'], box)\n",
    "        predicted_masks.append(seg_mask)\n",
    "\n",
    "    merged_mask = merge_masks(predicted_masks)\n",
    "\n",
    "    return results_info, merged_mask, expanded_boxes\n",
    "\n",
    "yolo_model_path = './trained_yolo/best.pt'\n",
    "sam_model_checkpoint_path = \"./SAM_model_checkpoint_test_5epochs.pth\"\n",
    "test_images_folder = \"./test/test_images/\"\n",
    "test_masks_folder = \"./test/test_masks/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "yolo_model = YOLO(yolo_model_path).to(device)\n",
    "\n",
    "model_config = SamConfig.from_pretrained(\"facebook/sam-vit-base\")\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "\n",
    "model_sam = SamModel(config=model_config).to(device)\n",
    "model_sam.load_state_dict(torch.load(sam_model_checkpoint_path))\n",
    "\n",
    "total_iou = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for filename in os.listdir(test_images_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        image_path = os.path.join(test_images_folder, filename)\n",
    "        results_info, merged_mask, expanded_boxes = process_image(image_path, yolo_model, model_sam, processor, device)\n",
    "\n",
    "        true_mask_path = os.path.join(test_masks_folder, filename)  # Assuming the mask filename matches the image filename\n",
    "        true_mask = np.array(Image.open(true_mask_path).convert(\"L\"))\n",
    "        true_mask = (true_mask > 0).astype(np.uint8)  # Binarize the mask\n",
    "        true_mask_resized = np.array(Image.fromarray(true_mask).resize((256, 256), Image.NEAREST))\n",
    "\n",
    "        iou = calculate_iou(merged_mask, true_mask_resized)\n",
    "\n",
    "        total_iou += iou\n",
    "        total_predictions += 1\n",
    "\n",
    "        print(\"IoU for\", filename, \":\", \"{:.3f}\".format(iou))\n",
    "\n",
    "        image_expanded = Image.open(results_info['path'])\n",
    "        draw_expanded = ImageDraw.Draw(image_expanded)\n",
    "        for box in expanded_boxes:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            draw_expanded.rectangle([x_min, y_min, x_max, y_max], outline=\"red\")\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image_expanded)\n",
    "        plt.title(\"Image with expanded bounding boxes\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(merged_mask, cmap='gray')\n",
    "        plt.title(\"Merged Prediction\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "average_iou = total_iou / total_predictions\n",
    "print(\"Average IoU: {:.3f}\".format(average_iou))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde8ebf",
   "metadata": {},
   "source": [
    "Inference on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4fb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import SamProcessor, SamModel, SamConfig\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def extract_results_info(results):\n",
    "    info_dict = {}\n",
    "    info_dict['path'] = results[0].path\n",
    "    info_dict['shape'] = results[0].orig_shape\n",
    "    boxes = results[0].boxes\n",
    "    bounding_boxes = boxes.xyxy.tolist()\n",
    "    converted_boxes = []\n",
    "    for box in bounding_boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        converted_boxes.append([x_min, y_min, x_max, y_max])\n",
    "    info_dict['bounding_boxes'] = converted_boxes\n",
    "    return info_dict\n",
    "\n",
    "def expand_bounding_boxes(bounding_boxes, image_shape, expansion_ratio=0.1):\n",
    "    expanded_boxes = []\n",
    "    for box in bounding_boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        new_x_min = max(0, x_min - width * expansion_ratio)\n",
    "        new_y_min = max(0, y_min - height * expansion_ratio)\n",
    "        new_x_max = min(image_shape[1], x_max + width * expansion_ratio)\n",
    "        new_y_max = min(image_shape[0], y_max + height * expansion_ratio)\n",
    "        expanded_boxes.append([new_x_min, new_y_min, new_x_max, new_y_max])\n",
    "    return expanded_boxes\n",
    "\n",
    "def perform_segmentation_with_box(image_path, box):\n",
    "    test_image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(test_image, input_boxes=[[box]], return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_sam(**inputs, multimask_output=False)\n",
    "    medsam_seg_prob = torch.sigmoid(outputs.pred_masks.squeeze(1))\n",
    "    medsam_seg_prob = medsam_seg_prob.cpu().numpy().squeeze()\n",
    "    medsam_seg = (medsam_seg_prob > 0.5).astype(np.uint8)\n",
    "    return medsam_seg\n",
    "\n",
    "def merge_masks(predicted_masks):\n",
    "    merged_mask = np.zeros_like(predicted_masks[0], dtype=np.uint8)\n",
    "    for mask in predicted_masks:\n",
    "        merged_mask = np.maximum(merged_mask, mask)\n",
    "    merged_mask[merged_mask != 0] = 1\n",
    "    return merged_mask\n",
    "\n",
    "def process_image(image_path, yolo_model, sam_model, sam_processor, device):\n",
    "    results = yolo_model.predict(source=[image_path], imgsz=512, conf=0.3, verbose=False)\n",
    "    results_info = extract_results_info(results)\n",
    "\n",
    "    image = Image.open(results_info['path'])\n",
    "    image_shape = image.size[::-1]\n",
    "\n",
    "    expanded_boxes = expand_bounding_boxes(results_info['bounding_boxes'], image_shape)\n",
    "\n",
    "    predicted_masks = []\n",
    "    for box in expanded_boxes:\n",
    "        seg_mask = perform_segmentation_with_box(results_info['path'], box)\n",
    "        predicted_masks.append(seg_mask)\n",
    "\n",
    "    merged_mask = merge_masks(predicted_masks)\n",
    "\n",
    "    return results_info, merged_mask, expanded_boxes\n",
    "\n",
    "yolo_model_path = './trained_yolo/best.pt'\n",
    "sam_model_checkpoint_path = \"./SAM_model_checkpoint_test_5epochs.pth\"\n",
    "image_path = \"./test/test_images/fusc_0035.png\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "yolo_model = YOLO(yolo_model_path).to(device)\n",
    "\n",
    "\n",
    "model_config = SamConfig.from_pretrained(\"facebook/sam-vit-base\")\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "\n",
    "\n",
    "model_sam = SamModel(config=model_config).to(device)\n",
    "\n",
    "model_sam.load_state_dict(torch.load(sam_model_checkpoint_path))\n",
    "\n",
    "results_info, merged_mask, expanded_boxes = process_image(image_path, yolo_model, model_sam, processor, device)\n",
    "\n",
    "image = Image.open(results_info['path'])\n",
    "draw = ImageDraw.Draw(image)\n",
    "for box in expanded_boxes:\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Image with expanded bounding boxes\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(merged_mask, cmap='gray')\n",
    "plt.title(\"Merged Prediction\")\n",
    "plt.axis('off')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
